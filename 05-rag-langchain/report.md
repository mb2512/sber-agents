# Отчёт о выполнении задания

## Название проекта

**RAG-ассистент Сбербанка** — Telegram-бот с RAG (Retrieval-Augmented Generation) для ответов на вопросы по документам Сбербанка о кредитах, вкладах и дебетовых картах.

### Краткое описание

Проект представляет собой интеллектуального ассистента на базе технологии RAG, который способен отвечать на вопросы пользователей на основе реальных документов Сбербанка. Бот использует векторный поиск для нахождения релевантной информации и языковую модель для генерации ответов с учётом контекста диалога.

## Вариант задания

**Базовый вариант**

## Реализованные возможности

- [x] **RAG на базе LangChain** — ответы на основе реальных документов
- [x] **Индексация PDF документов** — автоматическая обработка документов при старте
- [x] **Индексация JSON датасета** — загрузка и обработка структурированных Q&A пар
- [x] **Контекстный диалог** — понимание уточняющих вопросов с сохранением истории
- [x] **Query Transformation** — улучшение поисковых запросов с учётом истории диалога
- [x] **Приоритетный поиск по метаданным** — поиск точных и частичных совпадений по полю `question` перед векторным поиском
- [x] **Асинхронная обработка** — поддержка множества пользователей одновременно
- [x] **Логирование** — запись всех событий в файл для отладки
- [x] **Команды управления** — `/start`, `/help`, `/index`, `/index_status`
- [x] **Обработка ошибок** — таймауты, retry-логика, обработка сетевых ошибок
- [x] **Эксперименты с размерами чанков** — тестирование различных параметров разбиения документов
- [x] **Сравнение моделей эмбеддингов** — тестирование различных моделей для создания векторных представлений

## Технологический стек

### Основные технологии

- **Python 3.11+** — основной язык разработки
- **uv** — менеджер зависимостей и виртуального окружения
- **aiogram 3.x** — фреймворк для Telegram Bot API (polling)
- **LangChain** — фреймворк для построения RAG-приложений
- **langchain-openai** — интеграция LangChain с OpenAI-совместимыми API
- **langchain-community** — дополнительные компоненты (InMemoryVectorStore, JSONLoader, PyPDFLoader)
- **pypdf** — загрузка и парсинг PDF-документов
- **python-dotenv** — для работы с переменными окружения
- **jq** — обработка JSON для JSONLoader
- **Make** — автоматизация сборки и запуска

### Архитектурные компоненты

- **InMemoryVectorStore** — векторное хранилище в памяти
- **RecursiveCharacterTextSplitter** — разбиение документов на чанки
- **OpenAIEmbeddings** — создание векторных представлений документов
- **ChatOpenAI** — взаимодействие с LLM через OpenAI-совместимый API
- **ChatPromptTemplate** — шаблоны промптов для диалога
- **RunnablePassthrough** — цепочки обработки в LangChain

## Используемые модели

### Модели для генерации ответов

- **Fireworks**: `accounts/fireworks/models/gpt-oss-120b`
- **OpenRouter**: `openai/gpt-oss-20b:free` (альтернативный вариант)

### Модели для эмбеддингов

- **Fireworks**: `accounts/fireworks/models/qwen3-embedding-8b`
- **OpenRouter**: `openai/text-embedding-3-large` (альтернативный вариант)

### Модели для трансформации запросов

- Используется та же модель, что и для генерации ответов (настраивается через `MODEL_QUERY_TRANSFORM`)

## Эксперименты с индексацией

### Описание экспериментов с разными размерами чанков

#### Эксперимент 1: Разные размеры чанков

**Цель:** Понять, как размер чанка влияет на качество ответов.

**Обоснование:** PDF документы от Сбербанка содержат структурированную информацию. Маленькие чанки (500 символов) могут разбивать логически связанную информацию, а большие чанки (1500 символов) могут захватывать больше контекста, но быть менее релевантными.

**Варианты, которые были протестированы:**

1. **chunk_size=500, chunk_overlap=50** (базовый вариант)
   - Количество чанков: ~377
   - Стабильная работа, хорошая релевантность

2. **chunk_size=800, chunk_overlap=100** (текущий вариант)
   - Количество чанков: ~246 (для PDF)
   - Улучшенная обработка структурированных документов

3. **chunk_size=1500, chunk_overlap=150** (экспериментальный)
   - Меньше чанков, больше контекста
   - Риск снижения релевантности

**Вывод:** При изменении количества чанков показалось стабильнее работа с `chunk_size=500`, в остальных случаях работа бота часто была нестабильна и он переставал видеть то, что видел в 500.

#### Эксперимент 2: Сепараторы с учётом структуры документа

**Цель:** Попробовать разбиение с учётом структуры PDF документа.

**Обоснование:** Документы Сбербанка имеют чёткую структуру с разделами и пунктами. Использование специальных сепараторов может помочь сохранить логическую целостность информации.

**Реализованный вариант:**

```python
def split_documents(pages: list) -> list:
    """Разбиение документов с учетом структуры"""
    # Сепараторы для банковских документов
    # Пробуем разбивать по: двойным переносам строк, одинарным, пробелам
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=100,
        separators=[
            "\n\n\n",    # Тройной перенос - обычно разделы
            "\n\n",      # Двойной перенос - параграфы
            "\n",        # Одинарный перенос
            ". ",        # Конец предложения
            " ",         # Пробелы
            ""           # Символы
        ],
        keep_separator=True  # Сохраняем разделители для контекста
    )
    chunks = text_splitter.split_documents(pages)
    logger.info(f"Split into {len(chunks)} chunks")
    return chunks
```

**Результаты:**
- Улучшенное сохранение логической структуры документов
- Более релевантные чанки для банковских документов
- Успешное применение для PDF документов

## Работа с JSON датасетом

### Реализация загрузки JSON

Для работы с JSON датасетом была реализована функция `load_json_documents()`, которая использует `JSONLoader` из LangChain с поддержкой `jq` для извлечения данных.

**Основные особенности:**

1. **Использование JSONLoader с jq_schema:**
   ```python
   loader = JSONLoader(
       file_path=str(json_path),
       jq_schema='.[].full_text',  # Извлекаем full_text из каждого элемента
       text_content=False
   )
   documents = loader.load()
   ```

2. **Добавление метаданных:**
   - Каждый документ получает метаданные: `question`, `category`, `url`
   - Метаданные используются для приоритетного поиска точных совпадений

3. **Fallback на ручной парсинг:**
   - Если `jq` недоступен, используется ручной парсинг JSON
   - Обеспечивает работоспособность даже без дополнительных зависимостей

4. **Приоритетный поиск:**
   - Реализован поиск точных и частичных совпадений по полю `question` перед векторным поиском
   - Улучшает релевантность ответов для вопросов из JSON датасета

**Структура JSON датасета:**
```json
{
  "url": "https://...",
  "question": "Как заказать карту?",
  "answer": "...",
  "category": "Вопросы о дебетовых картах",
  "type": "individual_qa",
  "full_text": "Категория: ...\n\nВопрос: ...\n\nОтвет: ..."
}
```

### Скриншоты работы с вопросами про карты

![Работа бота с JSON - Скриншот 1](screenshots/photo1(работа_бота_json).JPG)

![Работа бота с JSON - Скриншот 2](screenshots/photo2(работа_бота_json).JPG)

## Сравнение моделей эмбеддингов

### Тестируемые модели

Были протестированы модели эмбеддингов от разных провайдеров:

**Fireworks:**
- **qwen3-embedding-8b** — основная используемая модель
  - Размерность эмбеддингов: 1024
  - Специализированная модель для создания векторных представлений
  - Хорошее качество для русскоязычных текстов
  - Поддержка контекста до 8K токенов

**OpenRouter/OpenAI:**
- **text-embedding-3-large** — модель OpenAI через OpenRouter
  - Размерность эмбеддингов: 3072
  - Высокое качество эмбеддингов
  - Универсальная модель с поддержкой множества языков
  - Требует API ключ OpenRouter

### Критерии оценки

- **Релевантность поиска** — насколько точно находятся релевантные чанки
- **Качество ответов** — точность и полнота ответов на основе найденных чанков
- **Стабильность работы** — отсутствие ошибок и таймаутов
- **Скорость индексации** — время создания векторных представлений
- **Поддержка русского языка** — качество работы с русскоязычными документами

### Таблица сравнения качества ответов

| Критерий | qwen3-embedding-8b (Fireworks) | text-embedding-3-large (OpenRouter/OpenAI) |
|----------|--------------------------------|---------------------------------------------|
| **Релевантность поиска** | ⭐⭐⭐⭐ Высокая | ⭐⭐⭐⭐⭐ Очень высокая |
| **Качество ответов на русском** | ⭐⭐⭐⭐⭐ Отличное | ⭐⭐⭐⭐ Хорошее |
| **Скорость индексации** | ⭐⭐⭐⭐ Быстро | ⭐⭐⭐ Средне |
| **Стабильность работы** | ⭐⭐⭐⭐⭐ Очень стабильная | ⭐⭐⭐⭐ Стабильная |
| **Размерность эмбеддингов** | 1024 | 3072 |
| **Стоимость использования** | Низкая (Fireworks) | Средняя (OpenRouter) |
| **Поддержка русского языка** | ⭐⭐⭐⭐⭐ Специализированная | ⭐⭐⭐⭐ Универсальная |

### Выводы

**Какая модель эмбеддингов лучше для русского языка:**

1. **qwen3-embedding-8b (Fireworks)** показала лучшие результаты для русскоязычных документов:
   - Более точное нахождение релевантных чанков для вопросов на русском языке
   - Специализированная оптимизация для работы с русским текстом
   - Стабильная работа без таймаутов
   - Быстрая индексация документов
   - Оптимальное соотношение качества и стоимости

2. **text-embedding-3-large (OpenRouter/OpenAI)** показала хорошие результаты, но:
   - Универсальная модель, не специализированная для русского языка
   - Более высокая размерность эмбеддингов (3072 vs 1024) требует больше ресурсов
   - Зависимость от внешнего API (OpenRouter)

**Рекомендация:** Для работы с русскоязычными документами Сбербанка рекомендуется использовать **qwen3-embedding-8b** от Fireworks, так как она показала лучшие результаты по релевантности поиска и качеству ответов на русском языке при оптимальной скорости и стабильности работы.

### Скриншоты сравнения качества эмбеддингов

![Качество эмбеддингов - Скриншот 3](screenshots/photo3(качество_эмбеддингов).JPG)

![Качество эмбеддингов - Скриншот 4](screenshots/photo4(качество_эмбеддингов).JPG)

## Дополнительные улучшения

### Оптимизация поиска

1. **Приоритетный поиск по метаданным:**
   - Сначала ищется точное совпадение по полю `question`
   - Затем частичное совпадение (70% совпадение ключевых слов)
   - Только после этого выполняется векторный поиск

2. **Улучшенная фильтрация:**
   - Исключение служебных слов при сравнении
   - Нормализация знаков препинания
   - Логирование процесса поиска для отладки

3. **Увеличение k для retriever:**
   - `RETRIEVER_K=10` (было 3) для лучшего покрытия релевантных чанков

### Обработка ошибок

1. **Таймауты:**
   - Настраиваемый `REQUEST_TIMEOUT` для HTTP запросов
   - Увеличенный таймаут для RAG обработки

2. **Retry-логика:**
   - Повторные попытки отправки сообщений в Telegram
   - Обработка сетевых ошибок

3. **Логирование:**
   - Детальное логирование процесса поиска
   - Предупреждения о проблемах с метаданными
   - Отслеживание качества найденных чанков

## Заключение

Проект успешно реализует базовый вариант задания с дополнительными улучшениями:

- ✅ Полноценная RAG-система на базе LangChain
- ✅ Поддержка PDF и JSON документов
- ✅ Контекстный диалог с query transformation
- ✅ Приоритетный поиск по метаданным
- ✅ Эксперименты с различными параметрами индексации
- ✅ Сравнение моделей эмбеддингов
- ✅ Устойчивая обработка ошибок и таймаутов

Бот готов к использованию и демонстрирует стабильную работу с документами Сбербанка.

